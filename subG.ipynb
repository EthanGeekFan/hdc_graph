{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get obgn-arxiv dataset\n",
    "# https://ogb.stanford.edu/docs/nodeprop/#ogbn-arxiv\n",
    "from ogb.nodeproppred import PygNodePropPredDataset\n",
    "\n",
    "dataset = PygNodePropPredDataset(name='ogbn-arxiv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of graphs: 1\n",
      "number of features: 128\n",
      "number of classes: 40\n",
      "number of nodes: 169343\n",
      "number of edges: 1166243\n"
     ]
    }
   ],
   "source": [
    "dataGraph = dataset[0]\n",
    "\n",
    "print(f\"number of graphs: {len(dataset)}\")\n",
    "print(f\"number of features: {dataset.num_features}\")\n",
    "print(f\"number of classes: {dataset.num_classes}\")\n",
    "print(f\"number of nodes: {dataGraph.num_nodes}\")\n",
    "print(f\"number of edges: {dataGraph.num_edges}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_intervals: 40\n",
      "num_bits: 256\n"
     ]
    }
   ],
   "source": [
    "# HDC stuff\n",
    "from hdc.bsc import BSC as HDC\n",
    "from hdc.hv import HDCRepresentation\n",
    "from hdc.itemmem import ItemMem\n",
    "from hdc.encoder import Encoder\n",
    "from hdc.levelencoder import LevelEncoder\n",
    "from tqdm import tqdm\n",
    "from typing import Type\n",
    "\n",
    "hdc = HDC\n",
    "N = 10240\n",
    "encoder = LevelEncoder(hdc, N, -1, 1, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HighResItemMem(ItemMem):\n",
    "    def __init__(self, hdc: type[HDCRepresentation], lr = 1) -> None:\n",
    "        super().__init__(hdc)\n",
    "        self.lr = lr\n",
    "    \n",
    "    def cache(self, key, hv):\n",
    "        key = int(key)\n",
    "        if key not in self.caches:\n",
    "            self.caches[key] = [np.zeros(len(hv)), 0]\n",
    "        if key not in self.mem:\n",
    "            sim = 0\n",
    "        else:\n",
    "            sim = self.hdc.dist(self.mem[key], hv)\n",
    "        self.caches[key][0] += hv * (1 - sim) * self.lr\n",
    "        self.caches[key][1] +=(1 - sim) * self.lr\n",
    "        \n",
    "    def decache(self, key, hv):\n",
    "        key = int(key)\n",
    "        if key not in self.caches:\n",
    "            self.caches[key] = [np.zeros(len(hv)), 0]\n",
    "        if key not in self.mem:\n",
    "            sim = 0\n",
    "        else:\n",
    "            sim = self.hdc.dist(self.mem[key], hv)\n",
    "        self.caches[key][0] -= hv * (1 - sim) * self.lr\n",
    "        self.caches[key][1] -= (1 - sim) * self.lr\n",
    "    \n",
    "    def build(self):\n",
    "        for key, cache_line in self.caches.items():\n",
    "            new_mem = self.hdc.normalize(cache_line[0] / cache_line[1])\n",
    "            self.mem[key] = new_mem if cache_line[1] > 0 else np.logical_not(new_mem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_hvs = [hdc.random_hypervector(N) for _ in range(dataGraph.num_features)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([290])\n",
      "torch.Size([2, 1672])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.utils import k_hop_subgraph\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def extract_subgraph(dataGraph, node_idx, depth):\n",
    "    # get the subgraph around the node\n",
    "    # node_idx: index of the node\n",
    "    # depth: depth of the subgraph\n",
    "    # return: subgraph\n",
    "    # the subgraph is all nodes and edges within depth of the node\n",
    "    # depth = 0 means only the node itself\n",
    "    # depth = 1 means the node and its neighbors\n",
    "    # depth = 2 means the node and its neighbors and their neighbors\n",
    "    # etc.\n",
    "    subset, edge_index, _, _ = k_hop_subgraph(node_idx, depth, dataGraph.edge_index)\n",
    "    return subset, edge_index\n",
    "\n",
    "# get the subgraph around the node\n",
    "node_idx = 0\n",
    "depth = 1\n",
    "subnodes, edge_index = extract_subgraph(dataGraph, node_idx, depth)\n",
    "print(subnodes.shape)\n",
    "print(edge_index.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_instance(features):\n",
    "    feature_hvs = []\n",
    "    for i in range(len(features)):\n",
    "        f = hdc.bind([id_hvs[i], encoder.encode(features[i])])\n",
    "        feature_hvs.append(f)\n",
    "    hv = hdc.bundle(feature_hvs)\n",
    "    return hv\n",
    "\n",
    "def encode_raw_nodes(dataGraph):\n",
    "    node_hvs = []\n",
    "    for i in tqdm(range(dataGraph.num_nodes)):\n",
    "        hv = encode_instance(dataGraph.x[i])\n",
    "        node_hvs.append(hv)\n",
    "    return node_hvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_edges(node_hvs, edge_index):\n",
    "    edge_hvs = []\n",
    "    for i in range(edge_index.shape[1]):\n",
    "        src = edge_index[0][i]\n",
    "        dst = edge_index[1][i]\n",
    "        hv = hdc.bind([node_hvs[src], node_hvs[dst]])\n",
    "        edge_hvs.append(hv)\n",
    "    return edge_hvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning\n",
    "# for each node, encode the subgraph around it\n",
    "def learn(node_hvs, dataGraph, depth, lr = 0.1, exisiting_mem = None):\n",
    "    itemmem = HighResItemMem(hdc, lr) if exisiting_mem is None else exisiting_mem\n",
    "    for i in tqdm(range(dataGraph.num_nodes)):\n",
    "        label = dataGraph.y[i].item()\n",
    "        _, edge_index = extract_subgraph(dataGraph, i, depth)\n",
    "        if edge_index.shape[1] == 0:\n",
    "            continue\n",
    "        edge_hvs = encode_edges(node_hvs, edge_index)\n",
    "        hv = hdc.bundle(edge_hvs)\n",
    "        if len(hv) == N:\n",
    "            # Test if the item is already in the mem\n",
    "            itemmem.build()\n",
    "            if label in itemmem.caches.keys():\n",
    "                pred = itemmem.query(hv)\n",
    "                if not pred or pred != label:\n",
    "                    # If mispredicted, add to label cache\n",
    "                    itemmem.cache(label, hv)\n",
    "                    # subtract from the mispredicted label cache\n",
    "                    itemmem.decache(pred, hv)\n",
    "                # if correct, do nothing\n",
    "            else:\n",
    "                # never seen this label before, add to label cache\n",
    "                itemmem.cache(label, hv)\n",
    "    itemmem.build()\n",
    "    return itemmem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_test(node_hvs, dataGraph, itemmem, depth):\n",
    "    rand_indices = np.random.choice(dataGraph.num_nodes, 1000, replace=False)\n",
    "    correct = 0\n",
    "    skipped = 0\n",
    "    for i in tqdm(rand_indices):\n",
    "        label = dataGraph.y[i].item()\n",
    "        _, edge_index = extract_subgraph(dataGraph, int(i), depth)\n",
    "        if edge_index.shape[1] == 0:\n",
    "            skipped += 1\n",
    "            continue\n",
    "        edge_hvs = encode_edges(node_hvs, edge_index)\n",
    "        hv = hdc.bundle(edge_hvs)\n",
    "        pred = itemmem.query(hv)\n",
    "        if pred == label:\n",
    "            correct += 1\n",
    "    return correct / (len(rand_indices) - skipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/169343 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 169343/169343 [08:23<00:00, 336.05it/s]\n"
     ]
    }
   ],
   "source": [
    "node_hvs = encode_raw_nodes(dataGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 169343/169343 [13:33<00:00, 208.28it/s]\n"
     ]
    }
   ],
   "source": [
    "mem1 = learn(node_hvs, dataGraph, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 169343/169343 [13:52<00:00, 203.50it/s]\n"
     ]
    }
   ],
   "source": [
    "mem2 = learn(node_hvs, dataGraph, 1, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 169343/169343 [13:54<00:00, 202.81it/s]\n"
     ]
    }
   ],
   "source": [
    "mem3 = learn(node_hvs, dataGraph, 1, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 169343/169343 [13:45<00:00, 205.11it/s]\n"
     ]
    }
   ],
   "source": [
    "mem4 = learn(node_hvs, dataGraph, 1, 0.01, mem2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 169343/169343 [14:55<00:00, 189.10it/s]\n"
     ]
    }
   ],
   "source": [
    "mem5 = learn(node_hvs, dataGraph, 1, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:04<00:00, 223.39it/s]\n"
     ]
    }
   ],
   "source": [
    "acc1 = rand_test(node_hvs, dataGraph, mem1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:04<00:00, 236.87it/s]\n"
     ]
    }
   ],
   "source": [
    "acc2 = rand_test(node_hvs, dataGraph, mem2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:05<00:00, 194.76it/s]\n"
     ]
    }
   ],
   "source": [
    "acc3 = rand_test(node_hvs, dataGraph, mem3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:04<00:00, 237.48it/s]\n"
     ]
    }
   ],
   "source": [
    "acc4 = rand_test(node_hvs, dataGraph, mem4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:04<00:00, 220.35it/s]\n"
     ]
    }
   ],
   "source": [
    "acc5 = rand_test(node_hvs, dataGraph, mem5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43381180223285487\n",
      "0.4780564263322884\n",
      "0.43010752688172044\n",
      "0.4534351145038168\n",
      "0.2229299363057325\n"
     ]
    }
   ],
   "source": [
    "print(acc1)\n",
    "print(acc2)\n",
    "print(acc3)\n",
    "print(acc4)\n",
    "print(acc5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "224w",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
